{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add module to path\n",
    "# move char2ind and ind2char in utils\n",
    "# load char2ind and ind2char from utils\n",
    "# load generate_text from inference\n",
    "\n",
    "# add function for module build from exported/checkpoint to module build utils \n",
    "\n",
    "# create module build utils, add build_module, add loss\n",
    "# load build_module from module build utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'training_checkpoints'\n",
    "SAVE_DIR = 'saved_model'\n",
    "METADATA_DIR = 'metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mappings(alphabet):\n",
    "\n",
    "  char2ind = {ch:ind for ind, ch in enumerate(alphabet)}\n",
    "  ind2char = {ind:char for ind, char in enumerate(alphabet)}\n",
    "\n",
    "  return alphabet, char2ind, ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(METADATA_DIR, 'alphabet.pkl'), 'rb') as f:\n",
    "    al, char2ind, ind2char = make_mappings(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in char2ind.keys():\n",
    "    assert ind2char[char2ind[ch]] == ch\n",
    "\n",
    "for ind in ind2char.keys():\n",
    "    assert char2ind[ind2char[ind]] == ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_UNITS = 1024\n",
    "EMBEDDING_DIM = 256\n",
    "VOCAB_SIZE = len(char2ind.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'training_checkpoints/ckpt_100'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)\n",
    "\n",
    "pred_model.load_weights(tf.train.latest_checkpoint(CHECKPOINT_DIR))\n",
    "\n",
    "pred_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (1, None, 256)            19968     \n_________________________________________________________________\ngru (GRU)                    (1, None, 1024)           3938304   \n_________________________________________________________________\ndense (Dense)                (1, None, 78)             79950     \n=================================================================\nTotal params: 4,038,222\nTrainable params: 4,038,222\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proviamo a tua peccata\ne reddissi il punto di que raggio si scesi:\nfatti quoi si partien ciò che vedi la.\n  Dintorno a questa stella quand'io fece\ndel vero il discreto veramente Fetro.\nAubbian di riso tutta; onde si mosse,\nrimane ancor di lui dica tolta,\nmontate dal mento al ciuffetto.\n  E tutti li altri essi e Poi che pur mal punge\nquelle scoglie due, in suo fede elesse.\n  Poi che le creature persone etterne, e quei, for ch'uno,\nseguitar lei per tuono la vita ria,\nremotorsi presso di qui tolle\ncol puggio, quando fui l'ottava e 'l quale,\nvolea parlar ti facea sí fiacqua,\no pregiorare a me si travolla:\n  ond'era crudelte furon combatte!»\n  Cosí m'ebbe ragiono aguto del poi c'han solo\nanzi che di Virgilio mi dislaia\nquanto veduta non cura, e poi fu la bona\ndell'umana natura per suo nido, e giú la cala;\n  tal era io con voglia accesi nome, ed anima che tanto scarsi,\ntant'era, bra che la sua barca»;\n  dal corpo mo i' te cosí fosse, e già voleva dirti:\n  chi è quel che credea\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(pred_model, start_string=u\"Proviamo \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            19968     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 78)             79950     \n",
      "=================================================================\n",
      "Total params: 4,038,222\n",
      "Trainable params: 4,038,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(SAVE_DIR, custom_objects={'loss': loss})\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Proviamo a cui passion chiamava, e dí e notte\nciò ch'om sí del ti torcer la tua balía.\n  Come saran sí diversa cen portai\ncose che vive della tua gravi,\nper approvarla, non per ferme e alto merto in cielo\nconventare infino al cerco, ond'è presso alla faccia che già grande là o,\nposar si poseon sí che trascorre\nda buon volere, a che va con la morte pessa\nnelle perco secondo si poteonnse piú di canta dura assalute\nper male adunante,\n  dove l'un temploco le bellezze etterne.\n  Insieme lenon sotto la sua parvenza,\nla ben guidata sopra la corda e lo verace penetrate».\n  «La faccia sua eran grto lalvaggiare inteso.\n  Dalla cintola in su tutto 'l viso bassi,\ncome spirava di colui è pieno.\n  Quelli ch'un spirto che dalla parte ond'el si trova\npagola per me: «Poi ch'è mia bella figura\nche piú di mille anime di lui il vel campo,\n  cosí li spirò: «Per piú che prima allora,\npur come li occhi ch'al piú alto non si venne\ndelle magile peggio, e di sotto\na poco a poco un'alme a riversato.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(new_model, start_string=u\"Proviamo \"))"
   ]
  }
 ]
}